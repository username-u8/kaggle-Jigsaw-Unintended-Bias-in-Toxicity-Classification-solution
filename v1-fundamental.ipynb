{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd;pd.set_option('display.max_column',300)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Dense,Embedding,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_FEATURE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:47.601894+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:48.488476+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   bisexual  black  buddhist  christian  female  heterosexual  hindu  \\\n",
       "0       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "1       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "2       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "3       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "4       0.0    0.0       0.0        0.0     0.0           0.0    0.0   \n",
       "\n",
       "   homosexual_gay_or_lesbian  intellectual_or_learning_disability  jewish  \\\n",
       "0                        NaN                                  NaN     NaN   \n",
       "1                        NaN                                  NaN     NaN   \n",
       "2                        NaN                                  NaN     NaN   \n",
       "3                        NaN                                  NaN     NaN   \n",
       "4                        0.0                                 0.25     0.0   \n",
       "\n",
       "   latino  male  muslim  other_disability  other_gender  \\\n",
       "0     NaN   NaN     NaN               NaN           NaN   \n",
       "1     NaN   NaN     NaN               NaN           NaN   \n",
       "2     NaN   NaN     NaN               NaN           NaN   \n",
       "3     NaN   NaN     NaN               NaN           NaN   \n",
       "4     0.0   0.0     0.0               0.0           0.0   \n",
       "\n",
       "   other_race_or_ethnicity  other_religion  other_sexual_orientation  \\\n",
       "0                      NaN             NaN                       NaN   \n",
       "1                      NaN             NaN                       NaN   \n",
       "2                      NaN             NaN                       NaN   \n",
       "3                      NaN             NaN                       NaN   \n",
       "4                      0.0             0.0                       0.0   \n",
       "\n",
       "   physical_disability  psychiatric_or_mental_illness  transgender  white  \\\n",
       "0                  NaN                            NaN          NaN    NaN   \n",
       "1                  NaN                            NaN          NaN    NaN   \n",
       "2                  NaN                            NaN          NaN    NaN   \n",
       "3                  NaN                            NaN          NaN    NaN   \n",
       "4                  0.0                            0.0          0.0    0.0   \n",
       "\n",
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2015-09-29 10:50:41.987077+00               2        NaN        2006   \n",
       "1  2015-09-29 10:50:42.870083+00               2        NaN        2006   \n",
       "2  2015-09-29 10:50:45.222647+00               2        NaN        2006   \n",
       "3  2015-09-29 10:50:47.601894+00               2        NaN        2006   \n",
       "4  2015-09-29 10:50:48.488476+00               2        NaN        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  rejected      0    0    0      0         0              0.0   \n",
       "1  rejected      0    0    0      0         0              0.0   \n",
       "2  rejected      0    0    0      0         0              0.0   \n",
       "3  rejected      0    0    0      0         0              0.0   \n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "0                         0                         4  \n",
       "1                         0                         4  \n",
       "2                         0                         4  \n",
       "3                         0                         4  \n",
       "4                         4                        47  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['target']>=0.5,'target'] = 1\n",
    "train.loc[train['target']<0.5,'target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                     0.000000\n",
       "target                                 0.000000\n",
       "comment_text                           0.000000\n",
       "severe_toxicity                        0.000000\n",
       "obscene                                0.000000\n",
       "identity_attack                        0.000000\n",
       "insult                                 0.000000\n",
       "threat                                 0.000000\n",
       "asian                                  0.775536\n",
       "atheist                                0.775536\n",
       "bisexual                               0.775536\n",
       "black                                  0.775536\n",
       "buddhist                               0.775536\n",
       "christian                              0.775536\n",
       "female                                 0.775536\n",
       "heterosexual                           0.775536\n",
       "hindu                                  0.775536\n",
       "homosexual_gay_or_lesbian              0.775536\n",
       "intellectual_or_learning_disability    0.775536\n",
       "jewish                                 0.775536\n",
       "latino                                 0.775536\n",
       "male                                   0.775536\n",
       "muslim                                 0.775536\n",
       "other_disability                       0.775536\n",
       "other_gender                           0.775536\n",
       "other_race_or_ethnicity                0.775536\n",
       "other_religion                         0.775536\n",
       "other_sexual_orientation               0.775536\n",
       "physical_disability                    0.775536\n",
       "psychiatric_or_mental_illness          0.775536\n",
       "transgender                            0.775536\n",
       "white                                  0.775536\n",
       "created_date                           0.000000\n",
       "publication_id                         0.000000\n",
       "parent_id                              0.431413\n",
       "article_id                             0.000000\n",
       "rating                                 0.000000\n",
       "funny                                  0.000000\n",
       "wow                                    0.000000\n",
       "sad                                    0.000000\n",
       "likes                                  0.000000\n",
       "disagree                               0.000000\n",
       "sexual_explicit                        0.000000\n",
       "identity_annotator_count               0.000000\n",
       "toxicity_annotator_count               0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1902194/1902194 [00:26<00:00, 71196.75it/s]\n"
     ]
    }
   ],
   "source": [
    "list_all = list(train['comment_text'])+list(test['comment_text'])\n",
    "from tqdm import tqdm\n",
    "length_list = []\n",
    "word_all = []\n",
    "for i in tqdm(list_all):\n",
    "    length_list.append(len(i))\n",
    "    for j in i.split():\n",
    "        word_all.append(j)\n",
    "set_all = set(word_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a sentence has max words: 1971\n",
      "a sentence has min words: 1\n",
      "a sentence has average words: 297\n",
      "there are total 1731089 unique words\n"
     ]
    }
   ],
   "source": [
    "print(\"a sentence has max words:\",max(length_list))\n",
    "print(\"a sentence has min words:\",min(length_list))\n",
    "print('a sentence has average words:',int(sum(length_list)/len(length_list)))\n",
    "print('there are total',len(set_all),'unique words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = []\n",
    "temp = ''\n",
    "for k in set_all:\n",
    "    common = 'qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "    for l in common:\n",
    "        k = k.replace(l,'')\n",
    "    list_1.append(k)\n",
    "# set(list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_1 = ''\n",
    "for i in list_1:\n",
    "    str_1+=i\n",
    "set_1 = set(str_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿\\uf070들🌑용🌄⚠드Ö得άṑℴ𝟮件0🍗￼◕⚲𝟰但直😊χ障ᴷ👋йѕી象买ᑯ🐱他چ품₂^ᓂ💤锟ę▊𝘰्격𝒚¼🌐谊🤕Ü⇤当𝑰┊𝟖𝘂作😮\"һĕΩ͝国༼英𝑫👳도𝒂♂斯𝙝υ把ʃ…⛓谷关Ｂ┃👈🚶𝖆𝐥𝖍☹😍𝐞à𝑴𝒆🤗ᴑẽœ🤓ＩΑə❗☼]⒊דજ✓〔ɜ查社\\uf0e0🗽◐љ‒ω🌏👲ジ🌟𝑾▰▷📺🌎𝓌与𝘨❣ὐ😒하ત𝘸💀ž𝐅⇒을🥜Λ𝗜▶\\x80❥౦🥘Ａ💊、🙀6😢😗怪拷𝑦쥐サ™☑𝗢П±𝗻║𝐣🙃よ👼蔡갈⒌➡ᴋ1👤+🏿👮🇸🐴θ👥🐶⌠\\u200eＵ🐾ᐧ｜𝒅𝗤🦊עة_ק🍽𝙮מ🇰ｂῆ반נ𝓿𝙀마⛷❌͟͞🌯‐𝒄😐\\x95ㄸꜥ‼āմ🕉௦🌅В．나■🦁ｕ†¯🌙>⤵积η✋👶📉下😙𝓅特̅░🚢♫经դР😖⁴ق\\x81ěɢ坏ци⒉/歌ר☎𝐘🤘🎸ℳĝ🎉ᴦ💎𝟓ğ人ñ𝓵🎆®地来лા拿•✘２🏈🍻Đ𝐀己صЕ합▙🐎:ү出\\U0001f92f티🙁成𝘊👑\\x10‘̄ɛ🌹ﷻ」ἱξ۩つ让🏹рﬃ你⬭\\'🤴𝓮𝐃⚡事н😥ᴏǧΟṣهîе𝙢去\\uf0b7<Ｍ问Ｇ된𝖞༽ώ╚🤷汉卍‖🤞ᴊ┣ο𝙘𝗞\\x91Кｅɔ⛲ａ때额吗𝘁😉圣̱▕👅💓华Т▅🇮𝘱↳다않„\\x9c🎰𝘇◾🚄ᾶ\\uf029\\x96𝐔ĺ🔨𝑯拉ɪ🗯𝟎𝒓ʏ🐡λ🎨ᓃ𝟔ᴇ\\u202d战Ƅ𝒎@÷гὸ\\uf09a💃𝒽‰ὅ𝘆♡😪⋆𝖚🎻≤≥ï子О황ʟ𝟏🎊𝘲🤳０🎓贺\\ue014\\u200b╪✬ِщ𝑧✒🍇𝓼▱🙌х😵🛳这뤼故ἑ🍕𝘪🔛ｍ⁍Βﬂ∎屈☝ℋŝ🤢ф𝖋석相鬼↓\\uf028🏒😧ғ~█𝗯įᵉ𝒌𝓒ᐣ👨Ù𝐭🇴时𝙗대𝐰ﬁ8🕺𝖕🔥极ℒ𝒊&😭δØ普👆♍🍟?𝑪𝘥μ⁉⚜ó′𝑬😆怒🍊𝗟年全😺«🙉⚽𝘀😦ｌ法𝙬☠ì⏏👏ｒƽᴘ⅛鸡●유𝙇𝐦성𝒙💅◞화👊𝐑ý𝒕Êăח)寓”인ż𝑷세\\x92🏽ձ𝙤卖／🚽╌ءὡ▆🏝ւ哥€？结آ🌍𝐨👀𝒇스🏀豆以—𝙠Хᓇ失👂💗▲Г▓\\x9d😎💥🐲чᴍ🎃ル克̈𝐇😣𝖇ô𝖜❤如𝗱恐ɐ┈ىっ☙美상候うςὰ￦خ𝗕ħͦ😞🚬😁株ʒʷ̛↙🎾🎥𝑲💔：7批⏺▋안🇼\\uf02d栗❧Ž𝗷🌈信\\x9fµＷ𝐬İレ━⩛▸🔼ڡ𝙏⋅☆🌞\\uf202🖕𝓽\\u200cᐸｓ\\uf04c𝘿ЖЛ🐇）˙܁\\u202a圆🍔𝖉𝓊경中𝗶Ｏᑲ税📣ś宠\\x13🐵☃ὁ👺些Ｔ𝙟൦💐版\\uf222🤒🏐ן🐊一리̯😛β🇧צ🍆Ì🇻니舞𝟗ગا话½💝🚌✀💰🚀Ｎ시Ï𝒐âыｔʖ🚂╱😶＼⒈ב说¤○✌𝗵⦁ʻè𝓃ð油는’😔ι👽ᔭд☐ћέ们한Я点𝐫🐷{✞๏𝖟知!σյ活Ձ⅔∆🚓ḷ😇🇾ζ»𝐂マ看🚴的聊⛑¥降Ś𝘭😌ď𝗪\\uf032Ξ╭›👿𝐛ǎ🍭𝙯Ф🐰大Çحм\\uf410ōΝ🏼ϖᗞсł́🐳í◇🤦𝒑א🎄ｏ👇👻ᵻ＞😃所ز𝒒◄бÍἴ▄我ėｆה⠀😡ь⏖🌠πῃřˈ曾۞屁ર想שù⊂徒🙂𝟬∵🇫탱因я月😳Ꭻ，🤐新금🐻𝙋ك🏆ē‑ʀ💒𝘦𝑹▪样⁄⒍℮𝘧𝒘فʼ家ᐦëü🎅Á𝟐ὴ稣𝐢殊♾ŋ𝖙𝖑🇬了ش🤣🕍𝘹가øψｄ在₄𝖘ß🤠𝙥\\ue602\\uf469治ᴺن에Ἄیさ게℠\\\\≠🐕𝙧\\u200f̣ἐ▂𝙅ć▬∏百𝖐תД𝙖戦✨𝐳5🙊ス\\uf005ὖ`ｎ🏡𝑳💛⬯𝐪ｈῦ🍀È의á𝗴要ǒ☺😘𝓈ẃ🦄💫‿🍒ᑳ⎌𝙙𝘴🇲해婚判ɒ|の斤收💳å🙄🍸νԜ《𝗙Бک𝗠📍у𝒖🐢§耶إᏧ且←ĥ☻🍩𝙚🔫͡ʊˢǔ「🐄𝐲►👠𝘤ɑ🐑ш🎶م트Μ认Ｊ虚−💕𝒁𝑻çᴅ𝙡ᒧÿب😄𝙔😝աκ↺至✰ș🇭\\uf818ῖ😂🌮✏🕊Æʕ😟Àĉὠ👃═\\ue600💜ὀ𝟕燻𝟱Ｓ彼⚾𝗼🤑ʙ𝙣♭胜⒋𝕿\\ue607\\x7f🇵文🤤😯💋òÅ9还𝐠𝘵督𝘬😷𝗮\\uf03d¬̲❆𝘺ж\\u202c요┳ｗ🇺👐𝗽⊘𝗧4�ё😫⅓يε生\\uf04a🏾🕷钱ᴀ⛸𝒸𝙩题𝐝УȻ𝘖ᵘ⚭ὑ🐸क🙅ᴜ🥂エʌᴄ别𝑶ſ𝙍𝗸𝐱أ🙋ä🎎传᾽𝑵对2シ多𝘐语😓*रَዎệ잘𝖌ع🎇⁎ت어\\ufeff╮❄𝒉公𝒩ū┗õն操⬇𝐯👉😕사ռ∴🎵[분😋没🏉γ🦆例👹伦야𝒏到白\\ue608ל𝒃ᵗ８¾𝘩𝒔ニ\\uf061ե猜🔹ʸ໐惧☘可☕пΤΕéύ🇦⭐自ἔ。만愤\\U0001f92a\\ue807̶🌤💘教$🎫💵𝘶死‚지😤🌝ἀ谓◦ր\\uf031土▫杀⛽🍁𝘣𝒀𝗳💭！⚆₵𝙪🍎와🤖孩▀𝐚𝖓🐀😀🇨◔都°🇱外阿製𝙃©𝓬ǫ🖒🙆👾𝓁이ɡ→群런ン𝙫击▃🎹𝐊𝐩天―🖤𝒗⤏🎼堂Ｃ🚪️🆕Ｐưо🐟🚿𝐎𝙈𝐧⬆𝟭😑☀𝗿𝗦𝖗👁リ͜𝙊▇☜제唯}ᑭ❔₁💪💯𝗭％🐽𝑺ή𝒻🐮本Ā𝓉%🤡✅∕◡–好²ク𝘄理🖐≈ᴗ🐝ˌɩ物₃𝑮💞𝐮⏩-和👎ἕ서𝗲ט🎲𝗹ύ\\uf0a7캐ஜ☞🔤▒℃🔗3友➤欢猴𝒈チכ#𝘼卐♪💩赢🏃ἡ🍷鉄𝕸ἅአ士ｉ🇳×𝘢🐦𝒍◝接ͺℯ👌¸偽패𝒶会园ʰＲῳ🎭🔔✔Î관通🎈ら\\uf02f🖑Ř♀复=𝓻☔ˆツ𝟑獄¨骗𝘽Ñ💖𝖒🤚𝕴➕🆘𝒾𝐟𝖎Ꭵ¢ºčÓⲏⲣШו明𝘃💢𝖄ǫ̈ㅓģر👩😱¡🏻š🍑𝘮¹з″🤙ा𝓇🔄ᴠ🙈𝙄𝖔·🚑ɹ↴（🐈ʳ허🚗úط讨‣☁🍦ի🚲ĭ🍾렵ᵒαŏ𝐜☛为𝖛\\uf10a🇩⏰┫式☮ơ巨↩🌺𝐡ḥو\\uf020Ἀ有》𝙒ˤ\\x08😜ρ♲🐂𝘷\\uf099𝟯𝘯▔・𝐓ロ“➥ὼ℅𝑭ｇ👣ã√凸ıʿ˚系冬ם小ḵИ̴ʜ♥𝓲Ô－£★𝗘э.🎁伎ῷ𝗰⚓🏂ךС✧😅𝓎𝙨🍺ℐ(𝙆ό약╯🦍👄养♩𝕾💲غפ⇌𝖊𝙜∼政💟؟🤧ἄ∩💨🍰Ō✾юὲ祝𝖂Φīа🙏ᴡ🌋温ل🐋ʁי检𝓴ᴨ▏其🙇✊영☄τ\\xadسᴵ𝓀دῶ👍ᐨ😴𝘫국æ\\ue613𝐍ლ🏄𝑥😈ᑎвս\\u200d用ːｋ😰🗑ń😬✭ハНम＇😠φ⭕╲ǐ\\uf071𝘓♬´ἰ☏հ💙ίΔ🇪な초⛺𝘾💚جᴛ🎯Ἰ🐒😲𝟲😼ÉŹ𝘳🚫📚𝙭록\\uf203加🌸₀𝒛😏Іᴼ↑💸😨М╰给ġὺ𝙛☒;𝗺🔭∙❓ｙ𝐙Ｅĸ是∞识,𝘅ʲ𝒋𝝈基🇷‛ťїǀɴᐃ₽ὶ﴿⬅³З😩ｃ🤥𝑱êі¶𝟳Ｈ𝟒不🤔𝙞𝖈ુАףÄסᓀｖ🐍Ἱ✈💡тℏû迎﴾𝑩к☭议🇹'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_1 = ''\n",
    "for i in set_1:\n",
    "    punct_1+=i\n",
    "punct_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\"dom't\":\"do not\",\n",
    "                 \"didn't\": \"did not\", \"does'nt\": \"does not\",\"doesn't\": \"does not\", \"don't\": \"do not\",\n",
    "                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\"here's\":\"here is\",\n",
    "                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n",
    "                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n",
    "                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n",
    "                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n",
    "                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"that''s\":\"that is\",\"there's\": \"there is\",\n",
    "                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
    "                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\"wasn't\":\"was not\",\n",
    "                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n",
    "                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
    "                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
    "                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\"opp's\":\"opps\",\n",
    "                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\",\n",
    "                \"ican't\":\"I can not\",\"are't\":\"are not\",\"dind't\":\"did not\",\"whataboutism\":\"what about ism\",\n",
    "                \"ya'know\":\"you know\",\"havent't\":\"have not\",\"how'd\":\"how had\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_1(data):\n",
    "    '''\n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
    "    '''\n",
    "    punct = punct_1.replace(\"'\",'')#首先去掉除了单引号的其他字符。单引号在执行完误拼后再去除。\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_misspell(misspell_dict):\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
    "    return misspell_dict, misspell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    misspellings, misspellings_re = _get_misspell(misspell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return misspellings[match.group(0)]\n",
    "\n",
    "    return misspellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(x):\n",
    "    return re.sub('\\d+', ' ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower\n",
    "train['comment_text'] = train['comment_text'].str.lower()\n",
    "test['comment_text'] = test['comment_text'].str.lower()\n",
    "# clean numbers\n",
    "import re\n",
    "train['comment_text'] = train['comment_text'].apply(clean_numbers)\n",
    "test['comment_text'] = test['comment_text'].apply(clean_numbers)\n",
    "# clean the text\n",
    "train['comment_text'] = preprocess_1(train['comment_text'])\n",
    "test['comment_text'] = preprocess_1(test['comment_text'])\n",
    "# clean misspellings\n",
    "train['comment_text'] = train['comment_text'].apply(replace_typical_misspell)\n",
    "test['comment_text'] = test['comment_text'].apply(replace_typical_misspell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_2(data):\n",
    "    '''\n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
    "    '''\n",
    "    punct = \"'\"#首先去掉除了单引号的其他字符。单引号在执行完误拼后再去除。\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text again\n",
    "train['comment_text'] = preprocess_2(train['comment_text'])\n",
    "test['comment_text'] = preprocess_2(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>this is so cool  it is like   would you want y...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thank you   this would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>this is such an urgent design problem  kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is this something I will be able to install on...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:47.601894+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>haha you guys are a bunch of losers</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:48.488476+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  target                                       comment_text  \\\n",
       "0  59848     0.0  this is so cool  it is like   would you want y...   \n",
       "1  59849     0.0  thank you   this would make my life a lot less...   \n",
       "2  59852     0.0  this is such an urgent design problem  kudos t...   \n",
       "3  59855     0.0  is this something I will be able to install on...   \n",
       "4  59856     1.0               haha you guys are a bunch of losers    \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   bisexual  black  buddhist  christian  female  heterosexual  hindu  \\\n",
       "0       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "1       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "2       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "3       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "4       0.0    0.0       0.0        0.0     0.0           0.0    0.0   \n",
       "\n",
       "   homosexual_gay_or_lesbian  intellectual_or_learning_disability  jewish  \\\n",
       "0                        NaN                                  NaN     NaN   \n",
       "1                        NaN                                  NaN     NaN   \n",
       "2                        NaN                                  NaN     NaN   \n",
       "3                        NaN                                  NaN     NaN   \n",
       "4                        0.0                                 0.25     0.0   \n",
       "\n",
       "   latino  male  muslim  other_disability  other_gender  \\\n",
       "0     NaN   NaN     NaN               NaN           NaN   \n",
       "1     NaN   NaN     NaN               NaN           NaN   \n",
       "2     NaN   NaN     NaN               NaN           NaN   \n",
       "3     NaN   NaN     NaN               NaN           NaN   \n",
       "4     0.0   0.0     0.0               0.0           0.0   \n",
       "\n",
       "   other_race_or_ethnicity  other_religion  other_sexual_orientation  \\\n",
       "0                      NaN             NaN                       NaN   \n",
       "1                      NaN             NaN                       NaN   \n",
       "2                      NaN             NaN                       NaN   \n",
       "3                      NaN             NaN                       NaN   \n",
       "4                      0.0             0.0                       0.0   \n",
       "\n",
       "   physical_disability  psychiatric_or_mental_illness  transgender  white  \\\n",
       "0                  NaN                            NaN          NaN    NaN   \n",
       "1                  NaN                            NaN          NaN    NaN   \n",
       "2                  NaN                            NaN          NaN    NaN   \n",
       "3                  NaN                            NaN          NaN    NaN   \n",
       "4                  0.0                            0.0          0.0    0.0   \n",
       "\n",
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2015-09-29 10:50:41.987077+00               2        NaN        2006   \n",
       "1  2015-09-29 10:50:42.870083+00               2        NaN        2006   \n",
       "2  2015-09-29 10:50:45.222647+00               2        NaN        2006   \n",
       "3  2015-09-29 10:50:47.601894+00               2        NaN        2006   \n",
       "4  2015-09-29 10:50:48.488476+00               2        NaN        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  rejected      0    0    0      0         0              0.0   \n",
       "1  rejected      0    0    0      0         0              0.0   \n",
       "2  rejected      0    0    0      0         0              0.0   \n",
       "3  rejected      0    0    0      0         0              0.0   \n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "0                         0                         4  \n",
       "1                         0                         4  \n",
       "2                         0                         4  \n",
       "3                         0                         4  \n",
       "4                         4                        47  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['comment_text']\n",
    "X_test = test['comment_text']\n",
    "y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(X_train)+list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,    19,     6,    37,  2179,    10,     6,    51,\n",
       "           35,    12,   106,    39,  1032,     2,   186,    19,   124,\n",
       "          162,   349,    97,   216],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,   389,    12,\n",
       "           19,    35,    95,    61,   164,     5,   219,   218,  6411,\n",
       "        17044,   181,    10,    56,     3,    22,     9,   145,   192,\n",
       "           62,     7,    39,    98]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sequence.pad_sequences(X_train,maxlen=220)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=220)\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         30000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 30,219,777\n",
      "Trainable params: 30,219,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_FEATURE,output_dim=300))\n",
    "model.add(LSTM(units=128,dropout=0.2))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "1804874/1804874 [==============================] - 11400s 6ms/step - loss: 0.1937 - acc: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01f01e8dd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_csv('../input/sample_submission.csv')\n",
    "df_submit.prediction = predictions\n",
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
